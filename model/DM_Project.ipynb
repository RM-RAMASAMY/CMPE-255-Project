{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XReXMw3coqEw"
      },
      "outputs": [],
      "source": [
        "%pip install pandas numpy scikit-learn gradio tensorboard >/dev/null "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import gradio as gr\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from tensorboardX import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = SummaryWriter(log_dir='./logs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MovieLens data set\n",
        "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
        "\n",
        "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
        "\n",
        "The data are contained in the files links.csv, movies.csv, ratings.csv and tags.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8as7Q1JErdfP",
        "outputId": "474e1e64-ef17-493d-be27-127755df5269"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# Upload and extract the ml-latest-small.zip file\n",
        "!wget -q https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "with ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Load the dataset\n",
        "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
        "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "\n",
        "# Check basic data\n",
        "print(\"Movies dataset shape:\", movies.shape)\n",
        "print(\"Ratings dataset shape:\", ratings.shape)\n",
        "movies.head(), ratings.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gif6PjHrfpN",
        "outputId": "bf0a94f1-2279-41d2-e274-de2ee56b518f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values in ratings:\", ratings.isnull().sum())\n",
        "\n",
        "# Remove duplicates if any\n",
        "ratings = ratings.drop_duplicates()\n",
        "\n",
        "# Create a user-item interaction matrix\n",
        "user_item_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n",
        "\n",
        "# Normalize the matrix (optional)\n",
        "#outlier detection needs to be done before normalization as it can affect the\n",
        "#standardScaler function output\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "user_item_matrix_scaled = scaler.fit_transform(user_item_matrix)\n",
        "\n",
        "# Convert the NumPy array to a pandas DataFrame\n",
        "user_item_matrix_scaled_df = pd.DataFrame(user_item_matrix_scaled)\n",
        "\n",
        "# Now you can use the head method\n",
        "display(user_item_matrix_scaled_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "8OICrHlArh_b"
      },
      "outputs": [],
      "source": [
        "# Define the custom RMSE scoring function\n",
        "def rmse_scorer(model, X, y):\n",
        "    # Predict ratings by multiplying user-item matrix with SVD components\n",
        "    predicted_ratings = model.transform(X).dot(model.components_)\n",
        "    # Compute RMSE\n",
        "    return np.sqrt(mean_squared_error(y, predicted_ratings))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOh-u50Arkqk",
        "outputId": "c654cfdd-d821-4710-8f08-8aa361e49baf"
      },
      "outputs": [],
      "source": [
        "# Apply Truncated SVD for matrix factorization\n",
        "svd = TruncatedSVD(n_components=50, random_state=42)\n",
        "svd_matrix = svd.fit_transform(user_item_matrix_scaled)\n",
        "\n",
        "# Convert the SVD results back into a DataFrame for easier understanding\n",
        "svd_df = pd.DataFrame(svd_matrix, index=user_item_matrix.index)\n",
        "\n",
        "# Show the SVD results\n",
        "display(svd_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9G9YSE6rne7",
        "outputId": "958c6148-c4ff-4705-edf3-9bb298c9b841"
      },
      "outputs": [],
      "source": [
        "# Perform cross-validation with RMSE scoring\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, test_index in kf.split(user_item_matrix_scaled):\n",
        "    X_train, X_test = user_item_matrix_scaled[train_index], user_item_matrix_scaled[test_index]\n",
        "    y_train, y_test = user_item_matrix_scaled[train_index], user_item_matrix_scaled[test_index]\n",
        "    svd.fit(X_train)\n",
        "    cv_scores = cross_val_score(svd, X_test, y_test, cv=kf, scoring=rmse_scorer)\n",
        "\n",
        "# Show the results\n",
        "print(\"Cross-validated RMSE scores:\", cv_scores)\n",
        "print(\"Mean RMSE:\", np.mean(cv_scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_factors = svd.transform(user_item_matrix_scaled)  # Shape: (n_users, n_components)\n",
        "item_factors = svd.components_.T                       # Shape: (n_items, n_components)\n",
        "\n",
        "print(\"User Factors (Reduced Representation):\\n\", user_factors)\n",
        "print(\"Item Factors (Reduced Representation):\\n\", item_factors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New user vector (9724 items), e.g., ratings or interactions\n",
        "new_user_vector = np.zeros((1, 9724))  # Single new user with all zeros\n",
        "# new_user_vector[0, [1, 3, 6, 10, 15]] = [4, 3, 5, 2, 1]  # Example ratings\n",
        "# Filter movies by a specific genre, e.g., 'Action'\n",
        "genre = 'Action'\n",
        "filtered_movies = movies[movies['genres'].str.contains(genre, case=False, na=False)]\n",
        "\n",
        "# Update the new user vector with average ratings for movies in the selected genre\n",
        "for movie_id in filtered_movies['movieId']:\n",
        "    avg_rating = np.mean(ratings[ratings['movieId'] == movie_id]['rating'])\n",
        "    new_user_vector[0, user_item_matrix.columns.get_loc(movie_id)] = avg_rating\n",
        "\n",
        "# Transform the new user into reduced space\n",
        "new_user_factors = svd.transform(new_user_vector)\n",
        "print(\"New User Factors:\\n\", new_user_factors)\n",
        "print(\"Shape of New User Factors:\", new_user_factors.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reconstruct the approximate user-item matrix\n",
        "reconstructed_matrix = np.dot(user_factors, item_factors.T)\n",
        "\n",
        "print(\"Reconstructed User-Item Matrix:\\n\", reconstructed_matrix)\n",
        "print(\"Shape of Reconstructed User-Item Matrix:\", reconstructed_matrix.shape)\n",
        "display(pd.DataFrame(reconstructed_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "w0cky17erp2E",
        "outputId": "f0b2fe09-a6cc-4248-ca64-b170a23a669a"
      },
      "outputs": [],
      "source": [
        "# Assume svd is already trained as shown in the previous part\n",
        "\n",
        "def recommend_movies(user_input):\n",
        "    # Step 1: Filter movies by genre based on user input\n",
        "    user_input = user_input.lower()\n",
        "    # Ensure we are considering only those movie_ids that are present in both ratings and movies table\n",
        "    common_movie_ids = set(ratings['movieId']).intersection(set(movies['movieId']))\n",
        "    filtered_movies = movies[movies['movieId'].isin(common_movie_ids) & movies['genres'].str.contains(user_input, case=False, na=False)]\n",
        "\n",
        "    # Step 2: Handle case when no movies are found for the genre\n",
        "    if filtered_movies.empty:\n",
        "        return [\"No movies found for this genre.\"]\n",
        "\n",
        "    # Step 3: Simulate a user vector with neutral ratings for simplicity\n",
        "    user_vector = np.zeros((1, user_item_matrix.shape[1]))  # Initialize with zeros for all movies\n",
        "\n",
        "    # Update the user vector with average ratings for movies in the selected genre\n",
        "    for movie_id in filtered_movies['movieId']:\n",
        "        avg_rating = np.mean(ratings[ratings['movieId'] == movie_id]['rating'])\n",
        "        user_vector[0, user_item_matrix.columns.get_loc(movie_id)] = avg_rating\n",
        "    \n",
        "    # Step 4: Get predicted ratings using the trained SVD model\n",
        "    predicted_ratings = svd.transform(user_vector).dot(svd.components_)\n",
        "\n",
        "    # Step 5: Get top 5 recommended movie titles\n",
        "    top_indices = np.argsort(predicted_ratings[0])[-15:][::-1]  # Sort and get top 5\n",
        "    recommended_movie_titles = movies.iloc[top_indices]['title'].tolist()\n",
        "\n",
        "    return recommended_movie_titles\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=recommend_movies,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Movie Recommendation System\",\n",
        "    description=\"Enter a genre or movie preference and get personalized movie recommendations.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()\n",
        "\n",
        "# recommend_movies(user_input=\"ACTION\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
